{\rtf1\ansi\ansicpg1252\cocoartf1038\cocoasubrtf360
{\fonttbl\f0\fnil\fcharset0 Monaco;}
{\colortbl;\red255\green255\blue255;\red191\green0\blue0;\red0\green0\blue191;\red0\green0\blue191;
\red0\green0\blue0;\red96\green96\blue96;\red0\green115\blue0;}
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\ql\qnatural\pardirnatural

\f0\fs36 \cf2 //Further effects examples: spatialization and other processing \cf0 \
\
\cf2 //use the internal server with the scope\cf0 \
\
(\
\cf3 Server\cf0 .default= s=\cf3 Server\cf0 .internal; \
s.waitForBoot(\{\
s.scope;\
\cf3 FreqScope\cf0 ();\
\});\
)\
\
\
\
\
\
\
Spatialization \
\
We'll pan some PinkNoise (which has some energy across the spectrum, without being the full equal power harshness of WhiteNoise), rather than a much harder to localise sine tone\
\
\cf2 //stereo panners: \cf0 \
\
\cf2 //equal power\cf0 \
\{\cf3 Pan2\cf0 .ar(\cf3 PinkNoise\cf0 .ar(0.2),\cf3 MouseX\cf0 .kr(-1,1))\}.scope\
\
\cf2 //compare linear crossfade, equal amplitude\cf0 \
\cf2 //drops in power in the middle\cf0 \
\{\cf3 LinPan2\cf0 .ar(\cf3 PinkNoise\cf0 .ar(0.2),\cf3 MouseX\cf0 .kr(-1,1))\}.scope\
\
\
\
\
\
\cf2 //multichannel: \cf0 \
\
\cf2 //sending to any loudspeaker\cf0 \
\
\cf2 //direct to speaker\cf0 \
\{\cf3 Out\cf0 .ar(1,\cf3 PinkNoise\cf0 .ar(0.1))\}.scope \cf2 //straight to right/second speaker\cf0 \
\
\cf2 //between speakers: \cf0 \
\
\cf2 //PanAz main arguments: numchannels, signal to pan, pan position from 0 to 2 around the ring of speakers\cf0 \
\{\cf3 PanAz\cf0 .ar(8,\cf3 PinkNoise\cf0 .ar(0.2),\cf3 MouseX\cf0 .kr(0,2))\}.scope;\
\
\
See Also:\
Pan4  quad panning\
Balance2 adjust stereo mix to bias towards left or right speaker\
Rotate2 rotate stereo mix circularly around two speakers\
\
\
Ambisonics UGens\
\
Ambisonics is a special format for representing spatial sound, modeling a sound and its strength on three dimensional axes (more generally, in higher order spherical co-ordinate systems). \
\
We go: \
\
sound -> encode Ambisonics format signal -> decode Ambisonics signal to a given speaker set-up. \
\
The Ambisonics format is speaker set-up independent, so you can design a piece in terms of intended spatial positioning, and (in theory) smoothly cope with different concert playback conditions. \
\
Basic in-built SuperCollider support for 'B-format' Ambisonics: \
\
\cf2 //demo in stereo, but could work with many more speakers\cf0 \
(\
\{\
	\cf3 var\cf0  w, x, y; \cf2 //a, b, c, d;\cf0 \
\
	\cf2 // B-format encode for 2 dimensional sound; PanB would work in three dimensions\cf0 \
	#w, x, y = \cf3 PanB2\cf0 .ar(\cf3 PinkNoise\cf0 .ar(0.2), \cf3 MouseX\cf0 .kr(-1,1)); \
	\
	\cf2 //stereo decode\cf0 \
	\cf3 DecodeB2\cf0 .ar(2,w,x,y); \
	\
	\cf2 // JMC example: B-format decode to quad\cf0 \
	\cf2 //#a, b, c, d = DecodeB2.ar(4, w, x, y);\cf0 \
	\cf2 //[a, b, d, c] // reorder to my speaker arrangement: Lf Rf Lr Rr\cf0 \
\}.play;\
)\
\
\
See also \
\
The Ambisonics extension libraries of Josh Parmenter\
\
\cf3 VBAP\cf0  \cf2 //in BEAST UGens, vector based amplitude panning, used for positioning sounds in an arbitrary 3D speaker configuration: works by considering triangles of speakers (like triangularization in computer graphics)\cf0 \
\
\
\
\
Simulation of space\
\
\
Modeling air absorption: high frequencies drop off more quickly in air. Filter the high frequencies more with distance, e.g. low pass filter where decrease cutoff frequency with distance. \
\
Also amplitude inversely proportional to distance (because intensity inversely proportional to distance squared) \
\
\cf2 //exaggerated a bit from reality, no doubt\cf0 \
(\
\{\
	\cf3 var\cf0  distance = \cf3 MouseX\cf0 .kr(1,100); \cf2 //1 to 100 metres\cf0 \
	\
	\cf3 LPF\cf0 .ar(\cf3 WhiteNoise\cf0 .ar(0.5),10000-(distance*80))/distance; \
	\
\}.scope\
)\
\
\
\
\
\
Doppler effect: pitch shift due to change of radial distance of object from observer\
\
\cf2 //reference sound\cf0 \
\{\cf3 Saw\cf0 .ar(440,0.2)\}.play\
\
\cf2 //starts above pitch, ends below pitch, due to cycle starts being closer together when approaching (reducing delay), and further apart when retreating (increasing delay)\cf0 \
(\
\{\
\cf3 var\cf0  radialdistance = \cf3 Line\cf0 .kr(10,-10,5,doneAction:2);\
\
\cf3 DelayC\cf0 .ar(\cf3 Saw\cf0 .ar(440,0.2),1.0, radialdistance.abs/340.0);\
	\
\}.scope\
)\
\
\
\
Doppler effect: pitch shift proportional to radial distance: \
\
\cf2 //path straight towards, through and away; get clear discontinuity\cf0 \
\cf2 //approximate speed of sound as 340 m/s\cf0 \
\cf2 //no frequency dependent filtering effects\cf0 \
(\
\{\
\cf3 var\cf0  source, radialdistance, absoluterd, dopplershift, amplitude; \
\
source= \cf3 Saw\cf0 .ar(\cf3 Demand\cf0 .kr(\cf3 Impulse\cf0 .kr(\cf3 LFNoise0\cf0 .kr(0.5,0.1,2)),0,\cf3 Dseq\cf0 ([63,60].midicps,\cf3 inf\cf0 )));	\cf2 //nee-naw emergency vehicle simulation\cf0 \
 \
\cf2 //in metres, moving at 6.8 metres per second\cf0 \
radialdistance= \cf3 EnvGen\cf0 .ar(\cf3 Env\cf0 ([34,-34],[10]),doneAction:2);\
\
absoluterd= radialdistance.abs;\
\
\cf2 //if something is 340 metres away, takes 1 second to get there; so make delay depend on distance away in metres\cf0 \
dopplershift= \cf3 DelayC\cf0 .ar(source, 1.0, absoluterd/340.0);\
\
\cf2 //inversely proportional\cf0 \
amplitude= (absoluterd.max(1.0)).reciprocal; \
\
\cf3 Pan2\cf0 .ar(amplitude*dopplershift,0.0)\
\}.play\
)\
\
\
\cf2 //More complicated: object will move past 5 metres to your right, on a line vertically down the page (as per ICM figure)\cf0 \
\cf2 //could add position dependent filtering for head shadow and separate delay to two ears...\cf0 \
(\
\{\
\cf3 var\cf0  source, distance, radialdistance, absoluterd, dopplershift, amplitude; \
\cf3 var\cf0  side, angle;\
\
source= \cf3 Saw\cf0 .ar(\cf3 Demand\cf0 .kr(\cf3 Impulse\cf0 .kr(\cf3 LFNoise0\cf0 .kr(0.5,0.1,2)),0,\cf3 Dseq\cf0 ([63,60].midicps,\cf3 inf\cf0 ))); \cf2 //nee-naw emergency vehicle simulation\cf0 \
 \
side=5;\
\cf2 //central side marker, placed 5 metres directly right of observer, observer facing ahead \cf0 \
\cf2 //in metres, moving at 6.8 metres per second\cf0 \
distance=  \cf3 EnvGen\cf0 .ar(\cf3 Env\cf0 ([34,-34],[10]), doneAction:2); \
\
angle= atan(distance/side);\
\
\cf2 //radial distance by \cf0 \
absoluterd= (distance.squared+ side.squared).sqrt; \
\
dopplershift= \cf3 DelayC\cf0 .ar(source, 1.0, absoluterd/340.0);\
\
\cf2 //inversely proportional\cf0 \
amplitude= (absoluterd.max(1.0)).reciprocal; \
\
\cf3 Pan2\cf0 .ar(amplitude*dopplershift,1.0)\
\}.play\
)\
\
\
\
\
\
\
\
\
\
\
\
\
Further sound transformation facilities\
\
\
\
Frequency shifting moves all frequency components of a sound, distorts harmonic relationships to inharmonic\
\
e.g. 100,200,300,400,500,600 Hz components, all moved by 70 Hz gives \
170,270,370,470,570,670 which are no longer in any simple harmonic relationship\
\
We know that we can get frequency shifting by using ring modulation, though there are two sidebands. As well as low pass filtering out the lower band in ring modulation, there is aso a technique called 'single side band modulation' via a technical device called the Hilbert transform. There are UGens for this: \
\
FreqShift.ar(input, amount of shift in Hz, phase shift)\
\
\cf2 //shift the harmonic set detailed above. No audible effect of phase shifts on sines\cf0 \
\{\cf3 FreqShift\cf0 .ar(\cf3 Mix\cf0 (\cf3 SinOsc\cf0 .ar(100*(1..6)))*0.1,\cf3 MouseX\cf0 .kr(0,1000),\cf3 MouseY\cf0 .kr(0,2pi))\}.scope;\
\
\
\cf2 //unless you wibble phase quickly enough\cf0 \
\{\cf3 FreqShift\cf0 .ar(\cf3 Mix\cf0 (\cf3 SinOsc\cf0 .ar(100*(1..6)))*0.1,\cf3 MouseX\cf0 .kr(0,1000),\cf3 SinOsc\cf0 .ar(\cf3 MouseY\cf0 .kr(0,100)))\}.scope;\
\
\
\cf2 //fun effects on audio input\cf0 \
\{\cf3 FreqShift\cf0 .ar(\cf3 SoundIn\cf0 .ar(0,0.1),\cf3 MouseX\cf0 .kr(0,3000),\cf3 SinOsc\cf0 .ar(\cf3 MouseY\cf0 .kr(0,100)))\}.scope;\
\
\
\
\
\
\
\
\
\
\
\
We mentioned the granular pitch shifter UGens PitchShift and Warp1 in passing back in the granular synthesis materials.\
\
Let's take a closer look at Warp1, which accomplishes granular time stretching and pitch shifting of the grains. \
\
b = \cf3 Buffer\cf0 .read(s,\cf4 Platform\cf5 .resourceDir +/+\cf6 "sounds/a11wlk01.wav"\cf0 ); \
\
\cf2 //overlaps eight windows of 0.1 seconds, so one window every 0.1/8 = 0.0125 seconds \cf0 \
\{\cf3 Warp1\cf0 .ar(1,b,pointer:\cf3 MouseX\cf0 .kr,freqScale:(2**(\cf3 MouseY\cf0 .kr(-2,2))),windowSize:0.1)\}.scope\
\
\cf2 //increasingly randomise window shape to avoid rough repetition sounds\cf0 \
\{\cf3 Warp1\cf0 .ar(1,b,pointer:\cf3 MouseX\cf0 .kr,freqScale:1.0,windowSize:0.1, windowRandRatio:\cf3 MouseY\cf0 .kr(0.0,0.9))\}.scope\
\
\
\
\
\
\
\
\
\
\
\
Building your own basic Overlap Add stretcher (requires Buffer b from above):\
\
\cf2 //define the windowed grains\cf0 \
(\
\cf3 SynthDef\cf0 (\cf7 \\windowofsound\cf0 ,\{\cf3 |out=0 dur=0.0 bufnum=0 amp=0.1 rate=1.0 pos=0.0 pan=0.0|\cf0 \
\cf3 var\cf0  env, source;	\
	\
env= \cf3 EnvGen\cf0 .ar(\cf3 Env\cf0 ([0,1,0],[0.5,0.5]*dur,\cf7 'sine'\cf0 ),doneAction:2); \
\cf2 //Env([0,1,0],[0.1,0.1],'sine').plot\cf0 \
	\
source = \cf3 PlayBuf\cf0 .ar(1,bufnum,\cf3 BufRateScale\cf0 .kr(bufnum)*rate,1.0,pos*\cf3 BufFrames\cf0 .ir(bufnum),loop:0); //don't allow loop \
	\
\cf2 //OffsetOut for sample accurate starts of grains\cf0 \
\cf3 OffsetOut\cf0 .ar(out,\cf3 Pan2\cf0 .ar(source*env,pan)); \
\}).add; \
)\
\
\
\cf2 //language side grain scheduling: accurate timing via s.bind\
//will move through the source file in the time given\
//small randomisations to grain size, amplitude and spacing used to avoid too much modulation noise from really strict window overlaps\cf0 \
(\
\cf3 var\cf0  playbacktime = 10.0; \
\cf3 var\cf0  grainsize= 0.1; \
\cf3 var\cf0  grainspersecond = 100; \cf2 //overlap factor of 10\cf0 \
\cf3 var\cf0  grainspacing = grainspersecond.reciprocal;\
\cf3 var\cf0  timedone; \
\cf3 var\cf0  proportion; \
\cf3 var\cf0  startrate=1.75; \
\cf3 var\cf0  endrate=0.25; \
\cf3 var\cf0  ratenow; \
\
\{\
	timedone = 0.0; \
	\
	while(\{timedone<playbacktime\},\{\
	\
	proportion = timedone/playbacktime; \cf2 //how far through the playback as a number from 0 to 1\cf0 \
	\
	\cf2 //proportion.postln;\cf0 \
	\cf2 //linear interpolation (can make exponential etc)\cf0 \
	ratenow = ((1.0-proportion)*startrate)  +  (proportion*endrate); \
	\cf2 //ratenow.postln;\cf0 \
	s.bind(\{	\cf3 Synth\cf0 (\cf7 \\windowofsound\cf0 ,[\cf7 \\dur\cf0 ,grainsize*rrand(1.0,1.1),\cf7 \\bufnum\cf0 ,b,\cf7 \\amp\cf0 ,rrand(0.09,0.11),\cf7 \\rate\cf0 ,ratenow,\cf7 \\pos\cf0 ,proportion]); \}); \
	\
	timedone = timedone + grainspacing + rrand(0.0,0.01); \
	\
	grainspacing.wait; \
	\
	\}); \
	\
\}.fork;\
)\
\
\
\
The PitchShift and Warp1 UGens just do this more efficiently under the hood. \
\
\
More complicated effects arise from particular sound analysis models. \
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
}